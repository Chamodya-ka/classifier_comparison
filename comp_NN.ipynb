{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05dc0749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4fe99c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/media/chamo/Backup Plus/WorkSpace/robocomp/ISL_Letters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca17fdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"csv_data/all_aug_csv_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "984ab098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 125</th>\n",
       "      <th>Unnamed: 126</th>\n",
       "      <th>Unnamed: 127</th>\n",
       "      <th>Unnamed: 128</th>\n",
       "      <th>Unnamed: 129</th>\n",
       "      <th>Unnamed: 130</th>\n",
       "      <th>Unnamed: 131</th>\n",
       "      <th>Unnamed: 132</th>\n",
       "      <th>Unnamed: 133</th>\n",
       "      <th>Unnamed: 134</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.491756</td>\n",
       "      <td>0.493280</td>\n",
       "      <td>0.552297</td>\n",
       "      <td>0.585863</td>\n",
       "      <td>0.485746</td>\n",
       "      <td>0.510742</td>\n",
       "      <td>0.563376</td>\n",
       "      <td>0.869506</td>\n",
       "      <td>0.458264</td>\n",
       "      <td>0.866527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K</td>\n",
       "      <td>0.287151</td>\n",
       "      <td>0.712849</td>\n",
       "      <td>0.287151</td>\n",
       "      <td>0.712849</td>\n",
       "      <td>0.287151</td>\n",
       "      <td>0.712849</td>\n",
       "      <td>0.287151</td>\n",
       "      <td>0.712849</td>\n",
       "      <td>0.287151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.495787</td>\n",
       "      <td>0.502158</td>\n",
       "      <td>0.506773</td>\n",
       "      <td>0.447959</td>\n",
       "      <td>0.482397</td>\n",
       "      <td>0.483892</td>\n",
       "      <td>0.385712</td>\n",
       "      <td>0.201435</td>\n",
       "      <td>0.293836</td>\n",
       "      <td>0.155573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K</td>\n",
       "      <td>0.145510</td>\n",
       "      <td>0.026687</td>\n",
       "      <td>0.145510</td>\n",
       "      <td>0.026687</td>\n",
       "      <td>0.145510</td>\n",
       "      <td>0.026687</td>\n",
       "      <td>0.145510</td>\n",
       "      <td>0.026687</td>\n",
       "      <td>0.145510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.637266</td>\n",
       "      <td>0.519966</td>\n",
       "      <td>0.697807</td>\n",
       "      <td>0.612550</td>\n",
       "      <td>0.631256</td>\n",
       "      <td>0.537429</td>\n",
       "      <td>0.708886</td>\n",
       "      <td>0.896192</td>\n",
       "      <td>0.603774</td>\n",
       "      <td>0.893214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K</td>\n",
       "      <td>-0.207268</td>\n",
       "      <td>-0.207268</td>\n",
       "      <td>-0.207268</td>\n",
       "      <td>-0.207268</td>\n",
       "      <td>-0.207268</td>\n",
       "      <td>-0.207268</td>\n",
       "      <td>-0.207268</td>\n",
       "      <td>-0.207268</td>\n",
       "      <td>-0.207268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.488338</td>\n",
       "      <td>0.490494</td>\n",
       "      <td>0.573976</td>\n",
       "      <td>0.621457</td>\n",
       "      <td>0.479837</td>\n",
       "      <td>0.515196</td>\n",
       "      <td>0.589648</td>\n",
       "      <td>1.022679</td>\n",
       "      <td>0.440963</td>\n",
       "      <td>1.018465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K</td>\n",
       "      <td>-0.016545</td>\n",
       "      <td>1.016545</td>\n",
       "      <td>-0.016545</td>\n",
       "      <td>1.016545</td>\n",
       "      <td>-0.016545</td>\n",
       "      <td>1.016545</td>\n",
       "      <td>-0.016545</td>\n",
       "      <td>1.016545</td>\n",
       "      <td>-0.016545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.491534</td>\n",
       "      <td>0.506994</td>\n",
       "      <td>0.555157</td>\n",
       "      <td>0.412425</td>\n",
       "      <td>0.486115</td>\n",
       "      <td>0.489743</td>\n",
       "      <td>0.575776</td>\n",
       "      <td>0.128571</td>\n",
       "      <td>0.470624</td>\n",
       "      <td>0.135086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17095</th>\n",
       "      <td>I</td>\n",
       "      <td>0.598435</td>\n",
       "      <td>0.745958</td>\n",
       "      <td>0.602551</td>\n",
       "      <td>0.712133</td>\n",
       "      <td>0.620573</td>\n",
       "      <td>0.694268</td>\n",
       "      <td>0.638618</td>\n",
       "      <td>0.694335</td>\n",
       "      <td>0.647868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.638957</td>\n",
       "      <td>0.717266</td>\n",
       "      <td>0.703855</td>\n",
       "      <td>0.722781</td>\n",
       "      <td>0.627691</td>\n",
       "      <td>0.716977</td>\n",
       "      <td>0.641996</td>\n",
       "      <td>0.878317</td>\n",
       "      <td>0.533294</td>\n",
       "      <td>0.874750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17096</th>\n",
       "      <td>I</td>\n",
       "      <td>0.517817</td>\n",
       "      <td>0.689921</td>\n",
       "      <td>0.521513</td>\n",
       "      <td>0.659549</td>\n",
       "      <td>0.537696</td>\n",
       "      <td>0.643508</td>\n",
       "      <td>0.553899</td>\n",
       "      <td>0.643567</td>\n",
       "      <td>0.562204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.554203</td>\n",
       "      <td>0.664158</td>\n",
       "      <td>0.612477</td>\n",
       "      <td>0.669110</td>\n",
       "      <td>0.544087</td>\n",
       "      <td>0.663899</td>\n",
       "      <td>0.556932</td>\n",
       "      <td>0.808771</td>\n",
       "      <td>0.459325</td>\n",
       "      <td>0.805568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17097</th>\n",
       "      <td>I</td>\n",
       "      <td>0.496239</td>\n",
       "      <td>0.292000</td>\n",
       "      <td>0.504085</td>\n",
       "      <td>0.326072</td>\n",
       "      <td>0.523979</td>\n",
       "      <td>0.345827</td>\n",
       "      <td>0.541905</td>\n",
       "      <td>0.347765</td>\n",
       "      <td>0.550147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.539696</td>\n",
       "      <td>0.325013</td>\n",
       "      <td>0.603581</td>\n",
       "      <td>0.326736</td>\n",
       "      <td>0.528532</td>\n",
       "      <td>0.324049</td>\n",
       "      <td>0.524838</td>\n",
       "      <td>0.165294</td>\n",
       "      <td>0.417203</td>\n",
       "      <td>0.156772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17098</th>\n",
       "      <td>I</td>\n",
       "      <td>0.847869</td>\n",
       "      <td>0.860848</td>\n",
       "      <td>0.851985</td>\n",
       "      <td>0.827024</td>\n",
       "      <td>0.870007</td>\n",
       "      <td>0.809159</td>\n",
       "      <td>0.888052</td>\n",
       "      <td>0.809225</td>\n",
       "      <td>0.897302</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888391</td>\n",
       "      <td>0.832157</td>\n",
       "      <td>0.953289</td>\n",
       "      <td>0.837672</td>\n",
       "      <td>0.877125</td>\n",
       "      <td>0.831868</td>\n",
       "      <td>0.891430</td>\n",
       "      <td>0.993208</td>\n",
       "      <td>0.782728</td>\n",
       "      <td>0.989641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17099</th>\n",
       "      <td>I</td>\n",
       "      <td>0.519957</td>\n",
       "      <td>0.712734</td>\n",
       "      <td>0.524097</td>\n",
       "      <td>0.678714</td>\n",
       "      <td>0.542223</td>\n",
       "      <td>0.660746</td>\n",
       "      <td>0.560373</td>\n",
       "      <td>0.660812</td>\n",
       "      <td>0.569676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560714</td>\n",
       "      <td>0.683876</td>\n",
       "      <td>0.625987</td>\n",
       "      <td>0.689424</td>\n",
       "      <td>0.549383</td>\n",
       "      <td>0.683586</td>\n",
       "      <td>0.563771</td>\n",
       "      <td>0.845860</td>\n",
       "      <td>0.454440</td>\n",
       "      <td>0.842272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17100 rows Ã— 135 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Unnamed: 1  Unnamed: 2  Unnamed: 3  Unnamed: 4  Unnamed: 5  \\\n",
       "0              K    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "1              K    0.287151    0.712849    0.287151    0.712849    0.287151   \n",
       "2              K    0.145510    0.026687    0.145510    0.026687    0.145510   \n",
       "3              K   -0.207268   -0.207268   -0.207268   -0.207268   -0.207268   \n",
       "4              K   -0.016545    1.016545   -0.016545    1.016545   -0.016545   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "17095          I    0.598435    0.745958    0.602551    0.712133    0.620573   \n",
       "17096          I    0.517817    0.689921    0.521513    0.659549    0.537696   \n",
       "17097          I    0.496239    0.292000    0.504085    0.326072    0.523979   \n",
       "17098          I    0.847869    0.860848    0.851985    0.827024    0.870007   \n",
       "17099          I    0.519957    0.712734    0.524097    0.678714    0.542223   \n",
       "\n",
       "       Unnamed: 6  Unnamed: 7  Unnamed: 8  Unnamed: 9  ...  Unnamed: 125  \\\n",
       "0        0.000000    0.000000    0.000000    0.000000  ...      0.491756   \n",
       "1        0.712849    0.287151    0.712849    0.287151  ...      0.495787   \n",
       "2        0.026687    0.145510    0.026687    0.145510  ...      0.637266   \n",
       "3       -0.207268   -0.207268   -0.207268   -0.207268  ...      0.488338   \n",
       "4        1.016545   -0.016545    1.016545   -0.016545  ...      0.491534   \n",
       "...           ...         ...         ...         ...  ...           ...   \n",
       "17095    0.694268    0.638618    0.694335    0.647868  ...      0.638957   \n",
       "17096    0.643508    0.553899    0.643567    0.562204  ...      0.554203   \n",
       "17097    0.345827    0.541905    0.347765    0.550147  ...      0.539696   \n",
       "17098    0.809159    0.888052    0.809225    0.897302  ...      0.888391   \n",
       "17099    0.660746    0.560373    0.660812    0.569676  ...      0.560714   \n",
       "\n",
       "       Unnamed: 126  Unnamed: 127  Unnamed: 128  Unnamed: 129  Unnamed: 130  \\\n",
       "0          0.493280      0.552297      0.585863      0.485746      0.510742   \n",
       "1          0.502158      0.506773      0.447959      0.482397      0.483892   \n",
       "2          0.519966      0.697807      0.612550      0.631256      0.537429   \n",
       "3          0.490494      0.573976      0.621457      0.479837      0.515196   \n",
       "4          0.506994      0.555157      0.412425      0.486115      0.489743   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "17095      0.717266      0.703855      0.722781      0.627691      0.716977   \n",
       "17096      0.664158      0.612477      0.669110      0.544087      0.663899   \n",
       "17097      0.325013      0.603581      0.326736      0.528532      0.324049   \n",
       "17098      0.832157      0.953289      0.837672      0.877125      0.831868   \n",
       "17099      0.683876      0.625987      0.689424      0.549383      0.683586   \n",
       "\n",
       "       Unnamed: 131  Unnamed: 132  Unnamed: 133  Unnamed: 134  \n",
       "0          0.563376      0.869506      0.458264      0.866527  \n",
       "1          0.385712      0.201435      0.293836      0.155573  \n",
       "2          0.708886      0.896192      0.603774      0.893214  \n",
       "3          0.589648      1.022679      0.440963      1.018465  \n",
       "4          0.575776      0.128571      0.470624      0.135086  \n",
       "...             ...           ...           ...           ...  \n",
       "17095      0.641996      0.878317      0.533294      0.874750  \n",
       "17096      0.556932      0.808771      0.459325      0.805568  \n",
       "17097      0.524838      0.165294      0.417203      0.156772  \n",
       "17098      0.891430      0.993208      0.782728      0.989641  \n",
       "17099      0.563771      0.845860      0.454440      0.842272  \n",
       "\n",
       "[17100 rows x 135 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d78f6a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db306d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['K', 0.0, 0.0, ..., 0.8695055246353149, 0.45826432108879106,\n",
       "        0.86652672290802],\n",
       "       ['K', 0.287150932926545, 0.712849067073455, ...,\n",
       "        0.201435081175821, 0.29383565743440504, 0.155572716017336],\n",
       "       ['K', 0.145509836224769, 0.026686885482796997, ...,\n",
       "        0.8961924101181121, 0.60377415731356, 0.8932136083908171],\n",
       "       ...,\n",
       "       ['I', 0.49623927528198497, 0.291999990019518, ...,\n",
       "        0.16529418705098498, 0.417203330054562, 0.15677166071947302],\n",
       "       ['I', 0.8478690993177008, 0.8608483080833499, ...,\n",
       "        0.9932081704109259, 0.782728315530927, 0.9896411900489879],\n",
       "       ['I', 0.519957319149694, 0.7127340321875072, ...,\n",
       "        0.8458597617517181, 0.45443961451098097, 0.8422721419501121]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c5459bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1bba24fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 0.0, 0.0, ..., 0.8695055246353149, 0.45826432108879106,\n",
       "        0.86652672290802],\n",
       "       [0.287150932926545, 0.712849067073455, 0.287150932926545, ...,\n",
       "        0.201435081175821, 0.29383565743440504, 0.155572716017336],\n",
       "       [0.145509836224769, 0.026686885482796997, 0.145509836224769, ...,\n",
       "        0.8961924101181121, 0.60377415731356, 0.8932136083908171],\n",
       "       ...,\n",
       "       [0.49623927528198497, 0.291999990019518, 0.504085080613437, ...,\n",
       "        0.16529418705098498, 0.417203330054562, 0.15677166071947302],\n",
       "       [0.8478690993177008, 0.8608483080833499, 0.8519853960858901, ...,\n",
       "        0.9932081704109259, 0.782728315530927, 0.9896411900489879],\n",
       "       [0.519957319149694, 0.7127340321875072, 0.524097433839536, ...,\n",
       "        0.8458597617517181, 0.45443961451098097, 0.8422721419501121]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e0d6f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "acfb1d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['K', 'K', 'K', ..., 'I', 'I', 'I'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6eae2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6879f3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "52788860",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = LabelBinarizer().fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6afe322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bdc8db5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "106f4d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2,stratify=Y,random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd058f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "97be24c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13680, 134) (3420, 134) (13680, 25) (3420, 25)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_val.shape, Y_train.shape, Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e54b1ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/chamo/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/chamo/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/chamo/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/chamo/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/chamo/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/chamo/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/chamo/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/chamo/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/chamo/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/chamo/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/chamo/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/chamo/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bc4f95dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/chamo/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:58: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/chamo/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:442: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/chamo/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3543: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units = 134 , activation = 'relu',input_shape=(134,)))\n",
    "model.add(Dense(units = 256 , activation = 'relu'))\n",
    "model.add(Dense(units = 256 , activation = 'relu'))\n",
    "model.add(Dense(units = 25 , activation = 'softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ec9fee51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9462dbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.5, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5f7e3c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/chamo/.local/lib/python3.6/site-packages/keras/optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/chamo/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2755: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/chamo/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2759: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0706f06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13680 samples, validate on 3420 samples\n",
      "Epoch 1/25\n",
      "13680/13680 [==============================] - 0s - loss: 0.0537 - acc: 0.9858 - val_loss: 0.0787 - val_acc: 0.9772\n",
      "Epoch 2/25\n",
      "13680/13680 [==============================] - 0s - loss: 0.0410 - acc: 0.9911 - val_loss: 0.0798 - val_acc: 0.9766\n",
      "Epoch 3/25\n",
      "13680/13680 [==============================] - 0s - loss: 0.0383 - acc: 0.9919 - val_loss: 0.0752 - val_acc: 0.9766\n",
      "Epoch 4/25\n",
      "13680/13680 [==============================] - 0s - loss: 0.0450 - acc: 0.9890 - val_loss: 0.1141 - val_acc: 0.9661\n",
      "Epoch 5/25\n",
      "13680/13680 [==============================] - 0s - loss: 0.0445 - acc: 0.9898 - val_loss: 0.0917 - val_acc: 0.9699\n",
      "Epoch 6/25\n",
      "13680/13680 [==============================] - 0s - loss: 0.0415 - acc: 0.9894 - val_loss: 0.0922 - val_acc: 0.9711\n",
      "Epoch 7/25\n",
      "13680/13680 [==============================] - 0s - loss: 0.0484 - acc: 0.9872 - val_loss: 0.0980 - val_acc: 0.9664\n",
      "Epoch 8/25\n",
      "13680/13680 [==============================] - 0s - loss: 0.0465 - acc: 0.9876 - val_loss: 0.0729 - val_acc: 0.9804\n",
      "Epoch 9/25\n",
      "13680/13680 [==============================] - 0s - loss: 0.0478 - acc: 0.9872 - val_loss: 0.0792 - val_acc: 0.9751\n",
      "Epoch 10/25\n",
      "13680/13680 [==============================] - 0s - loss: 0.0372 - acc: 0.9914 - val_loss: 0.0816 - val_acc: 0.9754\n",
      "Epoch 11/25\n",
      "13680/13680 [==============================] - 0s - loss: 0.0390 - acc: 0.9908 - val_loss: 0.0908 - val_acc: 0.9693\n",
      "Epoch 12/25\n",
      "13680/13680 [==============================] - 0s - loss: 0.0480 - acc: 0.9861 - val_loss: 0.0893 - val_acc: 0.9728\n",
      "Epoch 13/25\n",
      "13680/13680 [==============================] - 0s - loss: 0.0397 - acc: 0.9889 - val_loss: 0.0722 - val_acc: 0.9822\n",
      "Epoch 14/25\n",
      "13680/13680 [==============================] - 0s - loss: 0.0495 - acc: 0.9855 - val_loss: 0.0979 - val_acc: 0.9658\n",
      "Epoch 15/25\n",
      "13680/13680 [==============================] - 0s - loss: 0.0696 - acc: 0.9778 - val_loss: 0.1200 - val_acc: 0.9605\n",
      "Epoch 16/25\n",
      "13680/13680 [==============================] - 0s - loss: 0.0744 - acc: 0.9753 - val_loss: 0.1442 - val_acc: 0.9553\n",
      "Epoch 17/25\n",
      "13680/13680 [==============================] - 0s - loss: 0.1106 - acc: 0.9625 - val_loss: 0.1474 - val_acc: 0.9456\n",
      "Epoch 18/25\n",
      "13680/13680 [==============================] - 0s - loss: 0.1660 - acc: 0.9400 - val_loss: 0.1943 - val_acc: 0.9360\n",
      "Epoch 19/25\n",
      "13680/13680 [==============================] - 0s - loss: 0.0852 - acc: 0.9721 - val_loss: 0.1057 - val_acc: 0.9705\n",
      "Epoch 20/25\n",
      "13680/13680 [==============================] - 0s - loss: 0.0752 - acc: 0.9757 - val_loss: 0.1293 - val_acc: 0.9561\n",
      "Epoch 21/25\n",
      "13680/13680 [==============================] - 0s - loss: 0.1769 - acc: 0.9394 - val_loss: 0.2560 - val_acc: 0.9108\n",
      "Epoch 22/25\n",
      "13680/13680 [==============================] - 0s - loss: 0.1033 - acc: 0.9624 - val_loss: 0.1710 - val_acc: 0.9471\n",
      "Epoch 23/25\n",
      "13680/13680 [==============================] - 0s - loss: 0.0710 - acc: 0.9776 - val_loss: 0.1425 - val_acc: 0.9520\n",
      "Epoch 24/25\n",
      "13680/13680 [==============================] - 0s - loss: 0.0825 - acc: 0.9726 - val_loss: 0.1488 - val_acc: 0.9520\n",
      "Epoch 25/25\n",
      "13680/13680 [==============================] - 0s - loss: 0.0625 - acc: 0.9812 - val_loss: 0.1169 - val_acc: 0.9596\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,Y_train, batch_size = 256 ,epochs = 25 , validation_data = (X_val, Y_val) , callbacks = [learning_rate_reduction])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3e1ca09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./models/NN/III\") # in total 250 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "901dffa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1632/3420 [=============>................] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11687385259925971, 0.9596491228070175]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_val,Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ec08cd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "55cd4052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a=[]\n",
    "for x in X_val:\n",
    "    x=np.expand_dims(x,0)\n",
    "    a.append(np.argmax(model.predict(x)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dc3be6c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[137,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0, 137,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0, 135,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0],\n",
       "       [  0,   0,   0, 131,   0,   0,   0,   0,   0,   3,   0,   0,   0,\n",
       "          0,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0, 135,   0,   0,   0,   1,   0,   0,   0,   0,\n",
       "          0,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0, 135,   0,   0,   0,   1,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   1,   1,   0, 132,   0,   0,   1,   0,   0,   0,\n",
       "          0,   0,   0,   0,   2,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   2,   0, 116,   0,   0,   0,   8,   7,\n",
       "          0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 136,   0,   0,   0,   0,\n",
       "          1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   1,   0,   0,   0,   0,   0,   0, 135,   0,   0,   0,\n",
       "          0,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 136,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0, 133,   2,\n",
       "          0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   2,   0,   5,   0,   0,   0,   9, 117,\n",
       "          0,   0,   3,   1,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   2,   1,   0,   0,   0,   0,   0,   0,   1,\n",
       "        133,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   1,   0,   0,   0,   0,   0,   1,   0,   0,   0,\n",
       "          0, 134,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          8,   0, 127,   0,   2,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   2,   0,   0,   0,   9,   7,\n",
       "          0,   0,   0, 119,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,\n",
       "          0,   0,   2,   0, 134,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   1, 134,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          1,   0,   2,   0,   1,   0, 129,   0,   0,   0,   0,   4],\n",
       "       [  0,   0,   1,   0,   0,   1,   0,   0,   0,   0,   7,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0, 128,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   4,   2,   0,   1,   0,   0,   0,   1,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0, 127,   1,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   2,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0, 135,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   3,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 134,   0],\n",
       "       [  0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          1,   0,   0,   0,   2,   0,   0,   0,   0,   0,   0, 133]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(np.argmax(Y_val, axis=1), np.array(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebaaea6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
